from pydantic_ai import Agent, RunContext, UsageLimits

# from pydantic_ai.providers.openai import OpenAIProvider

# from pydantic_ai.models.openai import OpenAIChatModel

# from openai_client import openaiService



from loguru import logger

import sys
# import os
# from pydantic_ai.providers.openai import OpenAIProvider
# from pydantic_ai.models.openai import OpenAIChatModel
# from openai import AsyncOpenAI

from pydantic_ai.providers.google import GoogleProvider
from pydantic_ai.models.google import GoogleModel

import os
# ---------------- Logger setup ----------------

logger.remove()

logger.add(

    sys.stdout,

    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {message}"

)

logger.info("Starting the application...")

# ---------------- OpenAI (commented) ----------------

# openaiObj = openaiService()

# client, async_client = openaiObj._init_openai_client(

#     endpoint="https://gpt4ifx.icp.infineon.com"

# )

# llm = OpenAIProvider(openai_client=async_client)

# model = OpenAIChatModel("gpt-4o-mini", provider=llm)
# client = AsyncOpenAI(
#     api_key="your_api_key_here"  # Replace with your actual API key
# )


# # print(os.getenv("OPENAI_API_KEY"))

# provider = OpenAIProvider(openai_client=client)

# model = OpenAIChatModel(
#     model_name="gpt-5.2",  # cheaper + fast
#     provider=provider
# )

# client = AsyncOpenAI(
#     api_key="your api key here"  # hackathon mode
# )

# provider = OpenAIProvider(openai_client=client)

# model = OpenAIChatModel(
#     model_name="gpt-4o-mini",
#     provider=provider
# )
GEMINI_API_KEY = "your_api_key_here"  # Replace with your actual API key

provider = GoogleProvider(api_key=GEMINI_API_KEY)

model = GoogleModel(
    "gemini-2.5-flash",
    provider=provider
)



# ---------------- HuggingFace setup ----------------

logger.info("IFX hosted LLM Model initialized")

# ---------------- Joke selection agent ----------------

joke_selection_agent = Agent(

    model,

    system_prompt=(
        "Use the `joke_factory` to generate some jokes, at least 5, then select the best one. ",
        #  "Criteria to select one best joke include: dark humor, wordplay, clean humor, sarcasm, or absurdity. "
        # "You must return just a single joke."
        # "Generate 10 jokes. Score them by creativity and wordplay. "
    "Return only the best one."
    ),
)

logger.info("Joke selection agent initialized")

# ---------------- Joke generation agent ----------------



logger.info("Joke generation agent initialized")

joke_generation_agent=Agent(
   model, output_type=list[str]
)
@joke_selection_agent.tool

async def joke_factory(

    ctx: RunContext[None],

    count: int

) -> list[str]:

    print(ctx.usage)

    r = await joke_generation_agent.run(

        f"Please generate {count} jokes.",

        usage_limits=UsageLimits(

            request_limit=5,

            total_tokens_limit=1000

        ),

        usage=ctx.usage,

    )

    print(

        "\nJoke generated by the agent:\n",

        r.output,

        "\n\n"

    )

    return r.output

logger.info(

    "Added Joke Factory tool, which internally utilized joke generation agent"

)
result = joke_selection_agent.run_sync("Tell me the joke",
                                    usage_limits=UsageLimits(

        request_limit=5,

        total_tokens_limit=1000

    )

)
logger.info("Final joke selected by the joke selection agent:\n" + result.output)\
    